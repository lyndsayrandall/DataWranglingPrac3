---
title: "Data Wrangling (Data Preprocessing)"
author: "s9001731 Mark randall"
subtitle: "Practical Assessment 2"
date: "`r Sys.Date()`"
output:
  pdf_document: 
    extra_dependencies: booktabs
  html_document:
    df_print: paged
  html_notebook: default
  word_document: default
mainfont: Cambria
fontsize: 12pt
bibliography: bibliography.bibtex
link-citations: true
csl: "https://raw.githubusercontent.com/citation-style-language/styles/master/rmit-university-harvard.csl"
url: blue
header-includes:
 - \usepackage{wrapfig,amsmath,amssymb,setspace}
 - \usepackage{setspace}\singlespacing
 - \usepackage{paralist}
 - \let\itemize\compactitem
 - \usepackage{fancyhdr}
 - \usepackage{soul}
 - \usepackage{paralist}
 - \let\itemize\compactitem
 - \vspace{3mm}
 - \usepackage{titlesec}
 - \titlespacing{\section}{0pt}{8pt plus 1pt minus 1pt}{0pt plus 1pt minus 1pt}
 - \titlespacing{\subsection}{0pt}{8pt plus 1pt minus 1pt}{0pt plus 1pt minus 1pt}
 - \titlespacing{\subsubsection}{0pt}{8pt plus 1pt minus 1pt}{0pt plus 1pt minus 1pt} 
 - \usepackage{pdflscape}
 - \newcommand{\blandscape}{\begin{landscape}}
 - \newcommand{\elandscape}{\end{landscape}} 
---

```{r chunkGlobal, message=FALSE, warning=FALSE, include=FALSE, excho= FALSE}
knitr::opts_chunk$set(strip.white = TRUE,
                      comment = "",
                      warning = FALSE, 
                      message = FALSE)
```

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
library(openxlsx)
library(tidyr)
library(dplyr)
library(readr)
library(readxl)
library(knitr)
library(kableExtra)
library(tidyverse)
library(magrittr)
library(glue)
library(here)
library(tibble)
library(rvest)
library(tidyselect)
library(deductive)
library(deducorrect)
library(validate)
library(Hmisc)
library(stringr)
library(ggplot2)
library(ggnewscale)
library(moments)
library(sn)
library(purrr)
library(sf)
library(maptiles)
library(tidyterra)
library(OpenStreetMap)
library(geosphere)
library(scales)
library(egg)
library(outliers)
library(MVN)
library(moments)
library(forecast)
library(ggsci)
library(RColorBrewer)

# Remove files to await update

loaded_pkg <- c((.packages())) # Get loaded packages
if (file.exists("bibliography.bibtex")) {
  file.remove("bibliography.bibtex")
}
if (file.exists("tmp.bibtex")) {
  file.remove("tmp.bibtex")
}


```

```{r wrap-hook, message=FALSE, warning=FALSE,  echo = FALSE}
# Taken from https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.md
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = xfun::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

```

```{r chunk-hook, message=FALSE, warning=FALSE,  echo = FALSE}
#https://stackoverflow.com/questions/74914584/setting-code-chunk-size-on-quarto-pdf-output
default_chunk_hook  <- knitr::knit_hooks$get("chunk")

latex_font_size <- c("Huge", "huge", "LARGE", "Large", 
                     "large", "normalsize", "small", 
                     "footnotesize", "scriptsize", "tiny")

knitr::knit_hooks$set(chunk = function(x, options) {
  x <- default_chunk_hook(x, options)
  if (options$size %in% latex_font_size) {
    paste0("\n \\", options$size, "\n\n", 
      x, 
      "\n\n \\normalsize"
    )
  } else {
    x
  }
})

```

```{r CoverSheet,echo= FALSE, message=FALSE, warning=FALSE, out.width= "50%", out.height = "50%",fig.pos='H'}
  include_graphics("assignment-cover-sheet_Page_1.png")
  include_graphics("assignment-cover-sheet_Page_2.png")
```

## **Student names, numbers and percentage of contributions**

```{r studentNameTable, echo=FALSE}
na<- c(" Mark Randall")
no<- c(" s9001731")
pc<- c("100")

s<- data.frame(cbind(na,no,pc))
colnames(s)<- c("Student name", "Student number", "Percentage of contribution")

s %>% kbl(caption = "Group information") %>%
  kable_styling(latex_options = "HOLD_position")%>%
  kable_classic(full_width = F, html_font = "Cambria")
  
```

\newpage

## **Library Load**

```{r displayPackageRef, echo= FALSE, results="asis",out.width= "100%",tidy=TRUE, keep.source =FALSE, messages= FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='asis',collapse= TRUE,size = "tiny",fig.align="left"}

# Code snippet to list all loaded packages and reference them
# Iterate over vector to add a citation key, convert to Bibtex, and store

for (pkg in loaded_pkg) {
  tmp <- citation(pkg, auto = TRUE) # Get citation
  tmp$key <- paste0("R-",pkg) # Add cite key
  tmp_bib <- toBibtex(tmp) # Convert to Bibtex
  write(tmp_bib,file = "tmp.bibtex", append = TRUE, sep = "\n") # Write to file
} # write_bib, and write.bib did not do what I wanted.
#ENDNOTE_FILE <- read.bib("endnote_dw.txt") 
ans_copy_file <- file.copy("endnote_dw.txt","bibliography.bibtex")
ans_App_file <- file.append("bibliography.bibtex","tmp.bibtex")

count <- 1 # Establish package number
# Iterate over package list to add citation notation for R Markdown, and produce Markdown text.
for (pkg in loaded_pkg) {
  cite_text <- paste0(" [@R-",pkg,"]") # Create citation notation
  #Output R markdown 
  cat(paste0("Package ", count," : ", pkg ," ",cite_text,"  ")) # Double space at the end of a line forces \n
  cat("\n") # Not executed in rendering R-Markdown, see above
  count <- count + 1 # Increment package number 
}
rm(pkg,loaded_pkg)
```

```{r hiddenInputs,echo=FALSE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, messages= FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='asis',collapse= TRUE,size = "tiny",fig.align="left" }

csvFileNames <- list.files("../../Data",pattern = "*.csv", full.names = TRUE)
fullFileNames <- list.files("../../Data", full.names = TRUE)

#Create data frames fro csv files
vicRoadsDFList <- sapply(csvFileNames, function(incsv) read_csv(incsv,show_col_types = FALSE))
#Change Key of list to more HR form
names(vicRoadsDFList) <- c(gsub("../../Data/","", names(vicRoadsDFList)))

councilsVic_sf <- read_sf("../../Councils/georef-australia-local-government-area.geojson") %>% 
                  filter (ste_name == "Victoria")
namesLGAVic <- unique(councilsVic_sf$lga_name) %>%
               append(., "Merri-bek")

```

## **Abstract**

***"Most vehicular accidents in Victoria involve a male driver between 18 to 30 years of Age and a high powered car."***

|   This project will use some empirical data collected by the Victorian State Government[@RN94] to examine this statement.

## **Executive Summary**

|   Information that is absolutely needed is age and sex of the driver, power of the vehicle of all vehicles and drivers in an accident incident. The date, time, day, location of the accident and make of vehicle , if available, would assist in providing correlated causes.
|   At annex A is a preliminary exploration of the data files. Examining the tables results in the following:

-   From Accident.csv get date, time, day.
-   From Node.csv get latitude, longitude, and local government authority(LGA).
-   From Person.csv get sex, age group and road user. Also foreign key of vehicle id
-   From Vehicle.csv get year, make, model, and power.
  
|   These modified data frames are then scrutinised for:

-   Missing values, NAN, values.
-   Opportunities factors and ordered factors.
-   Conversion to a time-stamp if applicable.
-   Other anomalies.

|   After the initial inspection conduct a merge of the sub-data frames to one data frame and examine for "tidy" state. Then check to see if within ranges and final NA/NAN/INF and impute missing/out of range data..
|   Outliers were checked for certain attributes and dealt with.
|   Transformation of skewed attributes was then conducted.

## **Data**

```{r utilityFunc, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }
# Global Utility functions could be removed to source file.
checkNAInCols <- function(checkDF,checkDFVarNames) {
   chkedAllDFList <- list()
  for ( posn in 1:length(checkDF)) {
    chkIndDFList <- list()
    checkCol <- colnames(checkDF[[posn]])
    count <- 1
    for (inputCol in checkCol) {
      sumNA <- checkDF[[1]][inputCol] %>%
           summarise(numNa = sum(is.na(.)))
      if (is.numeric(checkDF[[1]][inputCol][[1]]) | is.integer(checkDF[[1]][inputCol][[1]])) {
        sumNAN <- sum(is.nan(checkDF[[1]][[inputCol]])) 
        sumINF <- sum(is.infinite(checkDF[[1]][[inputCol]]))
      }
      else {
        sumNAN <- 0
        sumINF <- 0
      }
      tmpSums <- list( sumNA = sumNA[[1]],
                   sumNAN = sumNAN[[1]],
                   sumINF = sumINF[[1]])
      tmpSumsByCol <- list(tmpColName = c(tmpSums))
      names(tmpSumsByCol) <- inputCol
      chkIndDFList <- append(chkIndDFList,tmpSumsByCol)
      count <- count + 1
    }
    tmpDFSUMCOLS <- list(tmpDFName = c(chkIndDFList))
    names(tmpDFSUMCOLS) <- checkDFVarNames[[posn]]
    chkedAllDFList <- append(chkedAllDFList,tmpDFSUMCOLS)
  }
  return(tmpDFSUMCOLS)
}

matrixNANANINF <- function(inputListsSums) {
  matrixDF <- matrix(NA, nrow = length(inputListsSums[[1]]), ncol = length(inputListsSums[[1]][[1]]))
  rownames(matrixDF) <- names(inputListsSums[[1]])
  colnames(matrixDF) <- names(inputListsSums[[1]][[1]])
  for (row in 1:length(inputListsSums[[1]])) {
    for (col in 1:length(inputListsSums[[1]][[1]])) {
      matrixDF[c(row),c(col)] <- inputListsSums[[1]][[row]][[col]]
    }
  }
  return(matrixDF)
}

dispHead <- function(chkAttrDf) {
  if (dim(chkAttrDf)[[1]] > 0) {
     res <- head(chkAttrDf,5)
  } else{
    res <- cat(paste(deparse(substitute(chkAttrDf)),"is empty.\n"))
  }
  return(res)
}

lat <- c( -39.2,-34)
long <- c(140, 150)

VICLATLONG <- c( lat,long) 
```

### **Accident.csv Data Frame**

```{r accDateTimeDay, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }
accDateTimeDay <- vicRoadsDFList$ACCIDENT.csv %>%
  select(ACCIDENT_NO,ACCIDENT_DATE,ACCIDENT_TIME,DAY_OF_WEEK,DAY_WEEK_DESC)
str(accDateTimeDay)
# Utility Function hidden to save page space. Code available on request.
chkDF1  <- checkNAInCols(list(accDateTimeDay), c("accDateTimeDay"))
# Utility Function hidden to save page space. Code available on request.
matrixDF1 <- matrixNANANINF(chkDF1)
matrixDF1 %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF1)}"),longtable = TRUE,
                format = "latex", booktabs = TRUE) %>%
          kable_styling(font_size = 8)
dayLabelsLevels <- c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday" ) 
accDateTimeDay %<>% mutate( Timestamp = lubridate::ymd_hms(paste(ACCIDENT_DATE,ACCIDENT_TIME),
                                                   tz = "Australia/Melbourne"),
                            Full_Day = factor(DAY_WEEK_DESC, ordered = TRUE,
                                                 levels = dayLabelsLevels,
                                                 labels = dayLabelsLevels),
                            Time_As_Float = round((as.numeric(format(Timestamp,"%H")) + 
                                            (as.numeric(format(Timestamp,"%M")))/60), digits = 2) ) %>%
                      rename(Date_char = ACCIDENT_DATE , Time_char = ACCIDENT_TIME) %>%
                    select(-c("DAY_OF_WEEK","DAY_WEEK_DESC"))
str(accDateTimeDay)
n_distinct(accDateTimeDay$ACCIDENT_NO)
rm(matrixDF1,chkDF1)
```

|   The date, time and day observations are extracted from the ACCIDENT.csv file. There are 168470 priamry accident identifiers.
|   The table returned shows that there are NA, NAN, Inf values in the original data frame. Mutate without problem.
|   The date and time are character representations. Mutate to add a posix object with local time zone of Australia/Melbourne.
|   Mutate to add an float value of time.
|   Change `DAY_WEEK_DESC` to an ordered factored list. Make the start day of the order as Monday to align with Federal government standards. Reduce column names to a more human readable and manageable form.

### **Node.csv Data Frame**

```{r accNode, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }
accNode <- vicRoadsDFList$NODE.csv %>%
  select(ACCIDENT_NO,LGA_NAME,LATITUDE,LONGITUDE)
str(accNode)
# Utility Function hidden to save page space. Code available on request.
chkDF2  <- checkNAInCols(list(accNode), c("accNode"))
# Utility Function hidden to save page space. Code available on request.
matrixDF2 <- matrixNANANINF(chkDF2)
matrixDF2 %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF2)}"),longtable = TRUE,
                format = "latex", booktabs = TRUE) %>%
          kable_styling(font_size = 8) 
str(accNode)
n_distinct(accNode$ACCIDENT_NO)
rm(matrixDF2,chkDF2)
```

|   There was no mutating of this data frame. There are 172242 unique accident identifiers.

### **Person.csv Data Frame**

```{r accPers, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }
accPerson <- vicRoadsDFList$PERSON.csv %>%
  select(ACCIDENT_NO,PERSON_ID, VEHICLE_ID,SEX, AGE_GROUP,ROAD_USER_TYPE_DESC)
str(accPerson)
# Utility Function hidden to save page space. Code available on request.
chkDF3  <- checkNAInCols(list(accPerson), c("accPerson"))
# Utility Function hidden to save page space. Code available on request.
matrixDF3 <- matrixNANANINF(chkDF3)
matrixDF3 %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF3)}"),
                    longtable = TRUE,format = "latex", booktabs = TRUE) %>%
              kable_styling(font_size = 8) 
str(accPerson)
n_distinct(accPerson$ACCIDENT_NO)
unique(accPerson$AGE_GROUP)
accPerson %<>% mutate(AGE_GROUP = factor(AGE_GROUP, ordered = TRUE,
                                             levels = c("0-4","5-12","13-15","16-17","18-21",
                                                       "22-25","26-29","30-39","40-49",
                                                       "50-59","60-64","65-69","70+","Unknown"))) %>%
              filter(ROAD_USER_TYPE_DESC %in% c("Drivers","Motorcyclists")) %>%
              group_by( by = ACCIDENT_NO) %>%
              pivot_wider(names_from = PERSON_ID, values_from = AGE_GROUP, 
                               names_prefix = "persId",names_sort = TRUE ) %>%
              ungroup()
# Utility Function hidden to save page space. Code available on request.
chkDF4  <- checkNAInCols(list(accPerson), c("accPerson"))
# Utility Function hidden to save page space. Code available on request.
matrixDF4 <- abs(-t(matrixNANANINF(chkDF4)))
matrixDF4[,1:10] %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF4)} Wider cols 1 to 10 "),
                    longtable = TRUE,format = "latex", booktabs = TRUE) %>%
              kable_styling(font_size = 6)
matrixDF4[,11:20] %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF4)} cols 11 to 20"),
                    longtable = TRUE,format = "latex", booktabs = TRUE) %>%
              kable_styling(font_size = 6)
matrixDF4[,21:30] %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF4)} cols 21 to 30"),
                    longtable = TRUE,format = "latex", booktabs = TRUE) %>%
              kable_styling(font_size = 6)
rm(matrixDF3,matrixDF4,chkDF4,chkDF3)
```

|   The initial data frame contained repetitive values for the person Id and the vehicle Id. This is suggestive that the data is stored in one table or a multitude of tables under column partition with the accident number as the primary key identifier. This limits the ability to interrogate the data for person and vehicles involved in many accidents.
|   The age group was set to an ordered factor. As per specification this data frame was set to "untidy" via a pivot wider. That is the observational row will contain multiple driver identifiers. The resultant NA/NAN/Inf interrogation table displays a large number of NA but not one column full of NA.

### **Vehicle.csv Data Frame**

```{r accVeh, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }
accVehicle <- vicRoadsDFList$VEHICLE.csv %>%
              select(ACCIDENT_NO,VEHICLE_ID,VEHICLE_YEAR_MANUF, VEHICLE_MAKE,VEHICLE_MODEL, VEHICLE_POWER,
              VEHICLE_TYPE_DESC, NO_OF_CYLINDERS) %>%
              mutate(NO_OF_CYLINDERS = as.integer(NO_OF_CYLINDERS),
                     VEHICLE_YEAR_MANUF = as.integer(VEHICLE_YEAR_MANUF))
str(accVehicle)
# Utility Function hidden to save page space. Code available on request.
chkDF5  <- checkNAInCols(list(accVehicle), c("accVehicle"))
# Utility Function hidden to save page space. Code available on request.
matrixDF5 <- matrixNANANINF(chkDF5)
matrixDF5 %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF5)}"),
                    longtable = TRUE,format = "latex", booktabs = TRUE) %>%
              kable_styling(font_size = 8)
vehMakes <- unique(accVehicle$VEHICLE_MAKE)
vehModel <- unique(accVehicle$VEHICLE_MODEL)
n_distinct(accVehicle$ACCIDENT_NO)
accVehicle %<>% select(-(VEHICLE_POWER))
rm(matrixDF5,chkDF5,vehMakes,vehModel)
```

|   The power attribute is non-existent in all observations, the only method to find this would be by brute force. It has been decided that this attribute is dropped. To achieve the analysis it is noted that the number of cylinders is only missing in 10.25% and there is a correlation between cylinders and power.
|   The year and number of cylinders have been converted to an integer value. There are missing or NA values resultant from the parse. An imputation of cylinders and year can be done from manufacturer and model. However `vehMakes` and `vehModel` on this data suggests that these input fields were not scrutinised to a data dictionary.

### **Merge the Data Frames**

#### **Phase One Merge Person with Vehicle**

|   The `accPerson` data frame forms the basis of the left side of the join argument. Pre-filtering for drivers(motorcyclists) has already occurred. The data frame will then be returned to a "tidy" state. That is the observational row will now only contain one person.
|   As part of the "tidy" the vehicle , person and join by identifiers will be removed. They are no longer of benefit and could jeopardise any modelling.

```{r combPersVehDFPH1, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }
accCombDF <- left_join(accPerson, accVehicle, by = c("ACCIDENT_NO","VEHICLE_ID")) %>%
             pivot_longer(cols = c(6:30),names_to = "Dvr_Id", values_to = "Age_Group" ) %>%
             filter(!is.na(Age_Group)) %>%
             select(-c("VEHICLE_ID","Dvr_Id","by"))
str(accCombDF)

```

#### **Merge Phase One with Temporal and Location Data Frames**

|   Temporal join was conducted with first followed by location. The location when first attempted threw an error of many to many relationship. This was examined and duplicate rows were found. It may have been prudent to pass the primary data frames threw `distinct()`, however given the "disjointed untidy" recording of data it is discounted. As it was unclear from the source data whether an accident could have two locations. That is if a car accident occured at X and the driver left the scene and caused an accident at Y is that still recorded with the same accident number.
|   Duplicated observations caused by location and duplicated location attribute rows were discarded.
|   Column names moved to a shorter more human readable form.

```{r combPersVehDF, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE,warnings= FALSE, message= FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }
accCombDF <- left_join(accCombDF, accDateTimeDay, by = c("ACCIDENT_NO"))
accCombDF <- left_join(accCombDF, accNode, by = c("ACCIDENT_NO"), relationship = "many-to-many") %>%
             distinct() 
colnames(accCombDF) <- c("Id","Gender","Dvr/Cyclist", "Veh_Year", "Veh_Make", "Veh_Model", "Veh_Type",
                         "Cylinders","Age_Group", "Date_char","Time_char" , "Timestamp",
                         "Full_Day","Time_Float","LGA_Name", "Latitude", "Longitude")

str(accCombDF)

```

#### **Add a further Correlated Field of Distance from a Point**

|   The distance from the Melbourne GPO will be added. Here an input could be established to determine accidents within a known black spot. The return from the check gave that all values longitude and latitude where within the earth spherical coordinate system, however NA were not examined. To add distances NA values filtered out and distance calculated via "geosphere" package.

```{r distGPO, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }

distToPointAcc <- function(fromLongLat, toLongLat) {
  
  calcDist <- geosphere::distVincentyEllipsoid(fromLongLat, toLongLat)
  return(calcDist)
}
#First Check If Long and Lat in -180 to 180, -90 to 90

chkLongLatEarth <- accCombDF %>% 
                    filter((Longitude <= -180 | Longitude >= 180) | 
                          (Latitude <= -90 | Latitude >= 90))
dispHead(chkLongLatEarth)
gpoMelbLatLong <- c(144.9627,-37.125)

accCombDF %<>% mutate(Dist_GPO =case_when( !((is.na(Longitude) | is.na(Latitude))) ~      
                                          mapply(function(inLong,inLat)
                                              distToPointAcc(gpoMelbLatLong,c(inLong,inLat)),
                                              Longitude,Latitude)) )
n_distinct(accCombDF$Id)
# Utility Function hidden to save page space. Code available on request.
chkDF6  <- checkNAInCols(list(accCombDF), c("accCombDF"))
# Utility Function hidden to save page space. Code available on request.
matrixDF6 <- abs(-t(matrixNANANINF(chkDF6)))
matrixDF6[,1:9] %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF6)} cols 1 to 9"),
                    longtable = TRUE,format = "latex", booktabs = TRUE) %>%
              kable_styling(font_size = 6)
matrixDF6[,10:17] %>% kable(caption = glue("Table of Sums of NA,NAN, and Inf for {names(chkDF6)} cols 10 to 18"),
                    longtable = TRUE,format = "latex", booktabs = TRUE) %>%
              kable_styling(font_size = 6)
missId <- setdiff(unique(accPerson$ACCIDENT_NO), unique(accNode$ACCIDENT_NO))
numMissing <- length(missId)

missingAccNo <- accCombDF %>%
                filter(Id %in% missId)
rm(matrixDF6,accDateTimeDay,accNode,accPerson, accVehicle,chkDF6)
```

|   The NA values in cylinders and year are accounted for by missing data in the `accVehicle` data frame. Imputation by brute force may add values; and goes beyond the time frame of this report.
|   The merged data frame,`accCombDF`, displays 146 observations without location, yet the `accNode` data frame displays

all observations with values. By executing `setdiff(unique(accPerson$ACCIDENT_NO), unique(accNode$ACCIDENT_NO))` and then conducting `length()` there are `r numMissing` values of `ACCIDENT_NO` that are different. Sub-setting those observations to `missingAccNo` allows an examination that concludes that the information to conduct the analysis is there; however any geo-positional plotting or analysis will require that these observations are removed.

## **Data Dictionary Merged Data Sets**

```{r dataDictionary, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }

accDFAttr <- colnames(accCombDF)
accDFType <- c("Character","Character", "Character", "Integer", "Character","Character","Character", "Integer",
               "Ordered Factor Character", "Date Format Y-m-d","hms num", "POSIXct","Ordered Factor Character",
               "Double","Character", "Double","Double","Double")
accDFDesc <- c("Unique Accident Identifier Starts with T followed by Year (T2024...).",
               "Gender of driver in accident.  Range M or F",
               "Whether Drivers or Motorcyclists.",
               "Year of Vehicle Manufacture.  Range 1908 to present",
               "Vehicle Manufacturer.",
               "Vehicle Model.",
               "Vehicle Body Type.",
               "Numbers of Cylinders of the vehicle. Range 1 to 12 (Special case for train, tram, horse, trailers = 0)",
               "Age Group of the driver.",
               "Date of Accident. Range 2012-01-01 to present",
               "Time of Accident. Range 0 to 12",
               "Timestamp. Range 2012-01-01 00:00:00.00 to present",
               "Day of Week. range Monday to Sunday",
               "Decimal time of Accident. Range 0 to 24",
               "Name of Local Government Authority.  See Victorian Government Source",
               "Latitude. Range -34 to -39.2",
               "Longitude. Range 140 to 150",
               "Distance Meters to Melb GPO. Greater or equal to 0")
accDFDataDict <- data.frame(cbind(accDFAttr, accDFType , accDFDesc))
colnames(accDFDataDict) <- c("Attribute", "Data Type", "Description")


accDFDataDict %>% kbl(caption = "Data Dictionary Victorian Road Accidents Distilled") %>% 
                  kable_styling( font_size= 8) %>%
                  column_spec(1,width="2.5cm") %>%
                  column_spec(2,width="2cm") %>%
                  column_spec(3,width="10cm") %>%
                  kable_classic(full_width = F)

rm(accDFAttr,accDFType,accDFDesc,accDFDataDict)
```

## **Check Ranges of Distilled Data Observations and Impute**

|   The following checks were done on the attributes of the data frame.

```{r attrChecks, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left" }

chkId <- accCombDF %>% filter(!str_detect(accCombDF$Id,"^T2")) 
dispHead(chkId)
chkGender <- accCombDF %>% filter(!accCombDF$Gender %in% c("M","F"))
dispHead(chkGender)  # 1.93 percent so deleted 
accCombDF %<>% filter(accCombDF$Gender %in% c("M","F"))
chkDvr <- accCombDF %>% filter(!`Dvr/Cyclist` %in% c("Drivers","Motorcyclists"))
dispHead(chkDvr)
chkVehYear <- accCombDF %>% filter(!(between(Veh_Year,1908,as.numeric(format(Sys.Date(),"%Y")))))

dispHead(chkVehYear) # Replace with the mean easy to impute. But if time brute force.
vehYearMean <- round(mean(accCombDF$Veh_Year, na.rm = TRUE),digits = 0)
accCombDF %<>% mutate(Veh_Year = case_when(!(between(Veh_Year,1908,as.numeric(format(Sys.Date(),"%Y"))))
                                          ~ vehYearMean,
                                          TRUE ~ Veh_Year))
chkCyl1 <- accCombDF %>% filter(!(Cylinders >= 1 & Cylinders <= 12)) 
dispHead(chkCyl1) # Best done by brute force intuition.
accCombDF %<>% mutate(Cylinders = case_when((Cylinders >= 60 & Cylinders < 70) ~ 6,
                                            (Cylinders == 88) ~ 8,
                                            (Id == "T20140005298" |Id == "T20210010866" ) ~ 4,
                                            (Id == "T20140015002"| Id == "T20180015095" |
                                             Id == "T20190004933" | Id == "T20230015484") ~ 6,
                                            (Id == "T20170016461") ~ 4,
                                            (Id == "T20150002025" |Id == "T20160020971"|
                                             Id == "T20180001536" |Id == "T20230019609"  ) ~2,
                                            TRUE ~ Cylinders
                                            ))
chkCyl2 <- accCombDF %>% filter(is.na(Cylinders))
dispHead(chkCyl2)
#unique(chkCyl2$Veh_Type)
accCombDF %<>% mutate(Cylinders = case_when((str_detect(Veh_Type,"Prime|Heavy|Truck") & 
                                                            is.na(Cylinders)) ~ 8,
                                             str_detect(Veh_Type, "Train|Tram|Horse|Parked") 
                                                                              ~ 0,
                                            (str_detect(Veh_Type, "Car|Taxi|Light") &
                                                            is.na(Cylinders)) ~ 4,
                                            (str_detect(Veh_Type, "Panel|Station|Utility|Other") &
                                                            is.na(Cylinders)) ~ 6,
                                            (str_detect(Veh_Type, "Bus|Plant") &
                                                            is.na(Cylinders)) ~ 6,
                                            (str_detect(Veh_Type, "Moped|Cycle|Scooter|Quad") &
                                                            is.na(Cylinders)) ~ 2,
                                            (str_detect(Veh_Type, "Car|Not|") &
                                                            is.na(Cylinders)) ~ 4,
                                            TRUE ~ Cylinders
                                           ))
#Age Group showing 0 NA not checked. Would show NA as factor.
# Next temporal attributes show no na, nan if check for range
chkDateChar <- accCombDF %>% filter(!(between(Date_char, ymd("2012-01-01"),now()))) 
dispHead(chkDateChar)
ChkTimeChar <- accCombDF %>% filter(!(between(hour(Time_char),0,24)))
dispHead(ChkTimeChar)
#Timestamp created as local Melbourne
chkTimestamp <- accCombDF %>% filter(!(between(Timestamp, ymd_hms("2011-12-31 24:00:0",
                                                                  tz  = "Australia/Melbourne"),now()))) 
dispHead(chkTimestamp)
chkDay <- accCombDF %>% filter(!(Full_Day %in% dayLabelsLevels ))
dispHead((chkDay))
chkTMFLoat <- accCombDF %>% filter(!(between(Time_Float,0.00, 24.00)))
dispHead((chkTMFLoat))
chkLGAName <- accCombDF %>% filter(!(LGA_Name %in% str_to_upper(namesLGAVic )))
dispHead((chkLGAName))
unique(chkLGAName$LGA_Name)
apineLGA <- c("(MOUNT HOTHAM)", "(FALLS CREEK)","(MOUNT BAW BAW)")
mansLGA <- c("MOUNT BULLER ALPINE RESOR","(MOUNT BULLER)","(MOUNT STIRLING)" )
accCombDF %<>% mutate(LGA_Name = case_when(LGA_Name == "GEELONG" ~ "GREATER GEELONG",
                                           LGA_Name == "BENDIGO" ~ "GREATER BENDIGO",
                                           LGA_Name == "DANDENONG"~ "GREATER DANDENONG",
                                           LGA_Name == "SHEPPARTON"~ "GREATER SHEPPARTON",
                                           LGA_Name %in% apineLGA ~ "ALPINE",
                                           LGA_Name %in% mansLGA ~ "MANSFIELD",
                                           LGA_Name == "(LAKE MOUNTAIN)"~ "MURRINDINDI",
                                           LGA_Name == "(MOUNT BAW BAW)" ~ "BAW BAW",
                                           LGA_Name == "(FRENCH ISLAND)" ~ "UNINCORPORATED VIC",
                                           TRUE ~ LGA_Name))
chkLat <- accCombDF %>% filter( is.na(Latitude) | !(between(Latitude,VICLATLONG[[1]],VICLATLONG[[2]])))
dispHead((chkLat))
chkLong <- accCombDF %>% filter(is.na(Longitude) |!(between(Longitude,VICLATLONG[[3]], VICLATLONG[[4]])))
dispHead((chkLong))
rm(chkCyl1,chkCyl2,chkDateChar,chkDay,chkDvr,chkGender,chkId,chkLat,
   chkLong,chkLongLatEarth,chkLGAName,chkTimestamp,chkTMFLoat,ChkTimeChar,chkVehYear)                                     
```

|   The following was conducted on the data frame:

-   Missing gender omitted as 1.93% of observations.Difficult to impute.\
-   Year of Manufacture of vehicle set to mean. Trivial but a lot quicker than brute force.\
-   Cylinders added by intuition of examination of observations, brute force. For those outside range. For those NA an intuitive type approach was taken.\
-   LGA Names were given the correct LGA nomenclature , imputed from location or left NA. Those left NA were for geo-spatial omission.\
-   Latitude and Longitude were within range except for NA which were again left NA for geo-spatial omission.

## **Check Outliers**

|   Outliers will be checked but not omitted. The reason for this is because the observations are what I classify as contained. That is ranges have been checked and deleting any outlier would negate the veracity of the analysis. The meaningful attributes would be cylinders and range. Most other numerical values are temporal. `Time_Float` is numerical but cyclic, ie. 23:99 is only 0.02 away from 00.01 on consecutive days, or 23.98. Similarly with days as they are cyclic.

```{r outliers, echo=TRUE,fig.pos='H',out.width= "100%", out.height = "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left",fig.cap= "Plots showing  distribution \nof attributes Of the DataFrame",fig.width = 8, fig.height= 6}
basePlot <- ggplot(accCombDF) +
            theme( axis.title.y = element_text(angle = 0, vjust = 0.5, size =6)) +
            theme( axis.title.x = element_text(angle = 0, vjust = 0.5, size =6)) +
            theme(plot.title = element_text(size = 6)) +
            theme(axis.text.y = element_text(face = "bold", colour = "blue",angle =0,size=6)) +
            theme(axis.text.x = element_text(face = "bold", colour = "blue",angle =45,size=6))
  
barAgeGp <- basePlot +
            geom_bar(aes(x = Age_Group)) +
            ggtitle("Bar Plot Age Group") 
barAgeGp2 <- accCombDF %>% filter(Age_Group %in% c("0-4","5-12","13-15","16-17")) %>%
            ggplot() +
            geom_bar(aes(x = Age_Group)) +
            ggtitle("Bar Plot Age \nGroup <=17")  +
            theme( axis.title.y = element_text(angle = 0, vjust = 0.5, size =6)) + 
            theme( axis.title.x = element_text(angle = 0, vjust = 0.5, size =6)) +
            theme(plot.title = element_text(size = 6)) +
            theme(axis.text.y = element_text(face = "bold", colour = "blue",angle = 90,size=6)) +
            theme(axis.text.x = element_text(face = "bold", colour = "blue",angle =45,size=6))
histTime <- basePlot +
            ggtitle("Histogram Time of day") +
            geom_histogram(aes(x = Time_Float)) 
histDist <- ggplot(accCombDF,aes(x = Dist_GPO, y = after_stat(density))) +
            geom_histogram( binwidth = 10) +
            geom_density(colour = "green", linewidth = 0.3) +
            ggtitle("Histogram Distance to GPO") + 
            scale_x_continuous(name = "Distance Kms",labels = function(x) x/1000 )  +
            theme( axis.title.y = element_text(angle = 0, vjust = 0.5, size =6)) + 
            theme( axis.title.x = element_text(angle = 0, vjust = 0.5, size =6)) +
            theme(plot.title = element_text(size = 6)) +
            theme(axis.text.y = element_text(face = "bold", colour = "blue",angle = 90,size=6)) +
            theme(axis.text.x = element_text(face = "bold", colour = "blue",angle =45,size=6))
histCyl <- basePlot +
           ggtitle("Histogram Cylinders") +
           geom_histogram(aes(x = Cylinders))
outDist <- basePlot + 
           geom_boxplot(aes( y = Dist_GPO)) + 
           ggtitle("Box Plot Distance to GPO") +  
           scale_y_continuous(name = "Distance Kms",labels = function(x) x/1000 )
outDist2 <- basePlot + 
            geom_boxplot(aes(x = Age_Group, y = Dist_GPO, colour = Gender)) + 
            ggtitle("Box Plot Age/ Distance to GPO") +  
            theme(axis.text.y = element_text(face = "bold", colour = "blue",angle = 45)) +
            scale_y_continuous(name = "Distance Kms",labels = function(x) x/1000 )
figure1 <- grid.arrange(outDist2, barAgeGp, barAgeGp2, histTime, histCyl, histDist, outDist,
                        nrow = 6, ncol = 3, layout_matrix = rbind(rbind(c(1,1,1),c(1,1,1)),
                                                                 rbind(c(2,3,4),c(2,3,4)),
                                                                 rbind(c(5,6,7),c(5,6,7))))
```

|    The second bar plot of the age group is given as it shows observations in the 0-4 and 5-12 grouping. These values are not omitted as there is a plausible case for there existence. That is a child may have been left alone in a vehicle and caused the accident.
|    Most attributes/observations in this data frame could be converted to a categorical type vector; except for distance from the GPO. And as can be seen from the plot it is heavily right skewed. If we wanted to use this in an analysis the smaller represented higher numbers would impact greatly on any out come. The next section will deal with attempting to regain a normal distribution for the attribute.  
|   The following code `maleAcc <- accCombDF %>% filter(Gender == "M" &  !(is.na(Dist_GPO))) %>%
  select(Time_Float,Dist_GPO) results <- mvn(data = maleAcc, multivariateOutlierMethod = "quan", showOutliers = TRUE)` was run but in a windows system a vector of more than 2 Gb causes problems. Investigation to remedial action is longer than time frame to submit report. 

## **Transform**

```{r transformDist, echo=TRUE,fig.pos='H',out.width= "100%", out.height = "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left",fig.cap= "Plots showing  distribution \nof attributes Of the DataFrame",fig.width = 8, fig.height= 5}
baseDistGPODF <- accCombDF %>% filter(!(is.na(Dist_GPO))) %>% select(Dist_GPO)
sqrtDist <- sqrt(baseDistGPODF)
cubertDist <- baseDistGPODF^(1/3)
recipDist <- 1/baseDistGPODF
bCDist <- BoxCox(baseDistGPODF, lambda = "auto")
log10Dist <- log10(baseDistGPODF)
distZScores <- sqrtDist %>%
  select(Dist_GPO) %>%
  outliers::scores(type = c("z"))
distZScores1 <- sqrtDist %>%
  select(Dist_GPO) %>%
  outliers::scores(type = c("z"))
distZScores2 <- cubertDist %>%
  select(Dist_GPO) %>%
  outliers::scores(type = c("z"))
distZScores3 <- recipDist %>%
  select(Dist_GPO) %>%
  outliers::scores(type = c("z"))
distZScores4 <- bCDist %>%
  select(Dist_GPO) %>%
  outliers::scores(type = c("z"))
distZScores5 <- log10Dist %>%
  select(Dist_GPO) %>%
  outliers::scores(type = c("z"))
sumMatrix <- as.matrix(cbind(summary(distZScores1),summary(distZScores2),
                       summary(distZScores3),summary(distZScores4),
                       summary(distZScores5),summary(distZScores)) ) 
colnames(sumMatrix) <- c("Sqare Root","Cube Root","Reciprocal","BoxCox","log10", "0riginal")
rownames(sumMatrix) <- NULL
kable(sumMatrix, caption= "Summary of Z Scores")
meanAccDistTrans <- c(mean(sqrtDist$Dist_GPO ,na.rm = TRUE),
                      mean(cubertDist$Dist_GPO ,na.rm = TRUE),
                      mean(recipDist$Dist_GPO ,na.rm = TRUE),
                      mean(bCDist$Dist_GPO ,na.rm = TRUE),
                      mean(log10Dist$Dist_GPO ,na.rm = TRUE),
                      mean(baseDistGPODF$Dist_GPO ,na.rm = TRUE))
medianAccDistTrans <- c(stats::median(sqrtDist$Dist_GPO ,na.rm = TRUE),
                        stats::median(cubertDist$Dist_GPO ,na.rm = TRUE),
                        stats::median(recipDist$Dist_GPO ,na.rm = TRUE),
                        stats::median(bCDist$Dist_GPO ,na.rm = TRUE),
                        stats::median(log10Dist$Dist_GPO ,na.rm = TRUE),
                        stats::median(baseDistGPODF$Dist_GPO ,na.rm = TRUE))
sdAccDistTrans <- c(stats::sd(sqrtDist$Dist_GPO ,na.rm = TRUE),
                    stats::sd(cubertDist$Dist_GPO ,na.rm = TRUE),
                    stats::sd(recipDist$Dist_GPO ,na.rm = TRUE),
                    stats::sd(bCDist$Dist_GPO ,na.rm = TRUE),
                    stats::sd(log10Dist$Dist_GPO ,na.rm = TRUE),
                    stats::sd(baseDistGPODF$Dist_GPO ,na.rm = TRUE))
skewAccDistTrans <- c(moments::skewness(sqrtDist$Dist_GPO ,na.rm = TRUE),
                      moments::skewness(cubertDist$Dist_GPO ,na.rm = TRUE),
                      moments::skewness(recipDist$Dist_GPO ,na.rm = TRUE),
                      moments::skewness(bCDist$Dist_GPO ,na.rm = TRUE),
                      moments::skewness(log10Dist$Dist_GPO ,na.rm = TRUE),
                      moments::skewness(baseDistGPODF$Dist_GPO ,na.rm = TRUE))
numOutAccDistTrans <- c(length(which(abs(distZScores1) > 3 )),
                        length(which(abs(distZScores2) > 3 )),
                        length(which(abs(distZScores3) > 3 )),
                        length(which(abs(distZScores4) > 3 )),
                        length(which(abs(distZScores5) > 3 )),
                        length(which(abs(distZScores) > 3 )))
transAccDF <- data.frame( transFun = c("Square root", "Cube Root", "Reciprocal", "BoxCox", "Log10","Original"),
                          mean = meanAccDistTrans,
                          median = medianAccDistTrans,
                          std_dev = sdAccDistTrans,
                          skew = skewAccDistTrans,
                          Outlier_Num = numOutAccDistTrans)
kable(transAccDF, caption = "Comarison of Transformations")

```

|    At figure 1  the  histogram plot of Distance Kms shows an extreme right or positive skew.  Accordingly only those transformation methods for positive skew were examined. At table 12 the transformations have reduced the maximums and minimums.  It appears that the BoxCox method reduced this range the most but has a high differential between the third quartile and maximum. This is followed by the square root method slightly larger maximum -minimum range , but lower third quartile to maximum lower.  The cube root has approximately the same maximum and minimum range but the lowest third quartile to maximum range.
|   Table 13 gives a different picture. The value of skew was calculated using the moments package skewness method(Agostino Test). The higher the number the greater the skew. The reciprocal method seems to be the best fit in term mean approaching median, and number of outliers but has a large skew number. The next best is the log10 method in mean approaching median, and number of outliers.  It also has the lower skew number.  
|   Given more time it would be propitious to understand the Agostino Test as it may weigh against the reciprocal solution. For this data set the log 10 method of transformation will be done on distance from the GPO.  

```{r transformDistMap, echo=TRUE,fig.pos='H',out.width= "100%", out.height = "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left",fig.cap= "Comparison Histograms",fig.width = 4, fig.height= 2}
accCombDF %<>% mutate(Dist_GPO = log10(Dist_GPO))
histDist2 <- ggplot(accCombDF,aes(x = Dist_GPO, y = after_stat(density))) +
            geom_histogram( binwidth = 0.05) +
            geom_density(colour = "green", linewidth = 0.3) +
            ggtitle("Histogram Distance to GPO") + 
            scale_x_continuous(name = "Distance Kms",labels = function(x) x/1000 )  +
            theme( axis.title.y = element_text(angle = 0, vjust = 0.5, size =6)) + 
            theme( axis.title.x = element_text(angle = 0, vjust = 0.5, size =6)) +
            theme(plot.title = element_text(size = 6)) +
            theme(axis.text.y = element_text(face = "bold", colour = "blue",angle = 90,size=6)) +
            theme(axis.text.x = element_text(face = "bold", colour = "blue",angle =45,size=6))
figure2 <- grid.arrange(histDist, histDist2, nrow = 1 , ncol = 2)
```

## **Conclusion**  
|   While the abstract has not been answered. This report to date has developed a data frame that will be able to provide the answer. It is also believed that this data frame could be able to to develop a model to predict accident probabilities given a set of attributes. It is believed by the author that the key features of this data frame would be:  
-   gender  
-   age group  
-   cylinders  
-   full day  
-   time as float  
-   distance from GPO(or any other point)
-   LGA  

|   A possible usage of such a model might be in the insurance industry to apply to premiums.
|   Attached at Annex B is an example of a geo-spatial plot that can be generated from this data frame.
|   The author acknowledges the effort in producing the data, but has a criticism in the missing values and seemingly lack of control in some entries.  It is also suggested that some form of relational map is developed, and data bases created. Again it is acknowledged that to fix twelve years would be an exhaustive task.

\newpage
\begin{flushright}
  \textbf{\ul{Appendix A to s9001731 Mark Randall}}\\
  \textbf{\ul{ Practical Assessment 2 of `r Sys.Date()`}}
\end{flushright}
\begin{center}
  \textbf{\ul{INITIAL EXAMINATION OF THE VICTORIAN ROAD CRASH DATA FILES}}
\end{center}
[@RN94]  
|   The Victoria Road Crash Data URL[@RN94] contains nine comma-separated value (csv) and one geo spatial java script object notation (GeoJSON) file. These were downloaded to a Data folder for examination. The files are:

```{r fileList,echo= TRUE, results="asis", tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100 ,size = "tiny"}
csvFileNames <- list.files("../../Data",pattern = "*.csv", full.names = TRUE)
fullFileNames <- list.files("../../Data", full.names = TRUE)

for (file in fullFileNames) {
  cat(paste("-\t", file,"\n"))
}
#Create data frames fro csv files
vicRoadsDFList <- sapply(csvFileNames, read.csv)
#Change Key of list to mor HR form
names(vicRoadsDFList) <- c(gsub("../../Data/","", names(vicRoadsDFList)))
```

|   The URL indicates that the metadata was updated 29 April 2024, data observations updated as at 27 November 2024 and that observations temporal start was 1 January 2012.

```{r duplicateACCKEY,echo= TRUE, results="asis",tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100 ,size = "tiny"}
posnOfDF <- 1
cat("These files have duplicated accident number keys in the data frame:")
for (tmpDF in vicRoadsDFList) {
  if (n_distinct(tmpDF$ACCIDENT_NO) < dim(tmpDF)[[1]]) {
    cat(paste("-\t",names(vicRoadsDFList)[[posnOfDF]],"\n"))
  }
  posnOfDF <- posnOfDF + 1
}
```

|    This would suggest that the `ACCIDENT_NO` key/attribute is a foreign key in these files.
|    The following is a lst of the attributes/column names by data frame.

```{r dfColNames, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='markup',collapse= TRUE,size = "tiny",fig.align="left"}
vecColNamesDF <- list()
posnCN <- 1
for (df in vicRoadsDFList) {
  vecColNamesDF[[names(vicRoadsDFList)[[posnCN]]]] <-  colnames(df)
   posnCN <- posnCN + 1
}
#https://stackoverflow.com/questions/60199801/how-to-view-a-list-like-table-style-in-r
max_len <- max(lengths(vecColNamesDF))
df <- purrr::map_df(vecColNamesDF, ~ c(., rep('', max_len - length(.))))
df[,1:5] %>% 
          kable(caption = "Attributes Files 1-5",longtable = TRUE,
                format = "latex", booktabs = TRUE) %>%
          kable_styling(font_size = 5) 
df[,6:9] %>% 
          kable(caption = "Attributes Files 6-9",longtable = TRUE,
                format = "latex", booktabs = TRUE) %>%
          kable_styling(font_size = 5) 
```

|    The following details those tables with common attribute names and what those names are.

```{r intersectDF, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='asis',collapse= TRUE,size = "tiny",fig.align="left" }
namesOfFile <- names(vecColNamesDF)
for (posnOne in 1:length(namesOfFile)) {
  cat(namesOfFile[[posnOne]],"at list no.",posnOne, "intersects with the following file:")
  cat("  \n")
  if (posnOne == length(namesOfFile)) {
    break
  }
  for (posnTwo in (posnOne + 1):length(namesOfFile)) {
   cat("-\t",namesOfFile[[posnTwo]],"at list no.",posnTwo," with these attributes:")
   cat("  \n")
   cat("\t\t-\t",intersect(vecColNamesDF[[posnOne]],vecColNamesDF[[posnTwo]]))
   cat("  \n")
    
    posnTwo <- posnTwo + 1
  }
  cat("  \n")
  posnOne <- posnOne + 1
  
}
```

|   Local Government Areas as at 2021 were found at OPENDATASOFT[@RN95].

```{r LGAVic, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='asis',collapse= TRUE,size = "tiny",fig.align="left"}
councilsVic_sf <- read_sf("../../Councils/georef-australia-local-government-area.geojson") %>% 
                  filter (ste_name == "Victoria")
namesLGAVic <- unique(councilsVic_sf$lga_name) %>%
               append(., "Merri-bek")
```

```{r mapVic, echo=TRUE,fig.pos='H',out.width= "100%",tidy=TRUE, keep.source =FALSE, tidy.opts=list(width.cutoff=55,keep.source=FALSE), linewidth= 100, results ='asis',collapse= TRUE,size = "tiny",fig.align="left", fig.show='hide', fig.keep='none'}
councilsVic_sf["Longitude"] <- sapply(councilsVic_sf$geo_point_2d, function(in2d) parse_number(strsplit(in2d,split = ":")[[1]][[2]]))
councilsVic_sf["Latitude"] <- sapply(councilsVic_sf$geo_point_2d, function(in2d) parse_number(strsplit(in2d,split = ":")[[1]][[3]]))
testOSMPlus1 <- councilsVic_sf[,c("Latitude", "Longitude")]
df1 <- st_as_sf(testOSMPlus1, crs=  "+proj=lonlat")
df_merc1<- st_transform(df1, 4326)
dc1 <- get_tiles(df_merc1, provider = "OpenStreetMap", zoom = 8)
maleAccDf <- accCombDF %>% filter(Gender == "M" & !(is.na(Dist_GPO))) %>% select(Dist_GPO,Age_Group, Longitude,Latitude)
mycolours = c(brewer.pal(name="BuPu", n = 9)[4:7], brewer.pal(name="Blues", n = 9)[5:9],brewer.pal(name="Oranges", n = 9)[4:9])
vicMaleMap <- ggplot() + geom_spatraster_rgb(data = dc1) +
  geom_sf(data = df1,aes( geometry = geometry), size =0.3, alpha= 0, color ="red") + 
  geom_point(data = maleAccDf, aes(x = Longitude, y = Latitude, colour = Age_Group), size = 0.1 ) +
  scale_color_manual(values = mycolours) + coord_sf(crs = 4326)
ggsave("vicmap.png" ,plot= vicMaleMap,width = 20, height = 15, units = "cm")

```

```{r purlChunk, echo = FALSE, messages = FALSE}
#knitr::purl("s9001731_Practical_Assessment_2_Annexures.Rmd")
endOfFile <- "end of file"
```

\newpage
\blandscape

  
\begin{figure}[b]
  \includegraphics[width = 23cm]{"vicmap1.png"}
  \caption{Accident Locations by Age Group Male}
\end{figure}

\elandscape
\newpage

## **Bibliography**
